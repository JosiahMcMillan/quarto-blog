---
title: "hypothesis testing nuances, by example"
subtitle: |
  todo
date: "2022-10-20"
categories: [hypothesis testing, frequentism, p-hacking]
draft: true
echo: false
fig-width: 10
fig-height: 6
---

**TL; DR**: We develop a hypothesis test to determine if a sequence of the coin flips comes from repeatedly flipping a fair coin. In the process, we discover lots of things that can go wrong.

So here's a homework problem that we recently gave out in an undergrad data science course. Suppose you have the following six sequences of coin flips. Exactly one sequence is generated by repeatedly flipping a fair coin. Which sequence is it?

```{r}
#| echo: true

sequences <- c(
  A = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHTHTHTHHTTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHTTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTH",
  B = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT",
  C = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH",
  D = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH",
  E = "HHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTHHHHHHHHTTTTTTTHHHHHHHHHTTTTTTTTTHHHHHHHHTTTHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHHTTTTTTTTTTHH",
  F = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"
)
```

::: callout-important
## Recommendation

Try to solve this problem on your own before reading on!
:::

To make the problem a little more concrete, here's a visualization of the coin flip sequences. Which one looks genuinely random to you?

```{r}
#| label: fig-observed
#| fig-cap: TOOD
#| message: false
#| warning: false
#| column: body-outset
library(tidyverse)
library(glue)

theme_set(theme_classic(16))

observed_nested <- tibble(
  name = glue("Seq {LETTERS[1:6]}"),
  sequence = sequences
) |> 
  mutate(
    result = str_split(sequence, "")
  )

observed_long <- observed_nested  |> 
  select(-sequence) |> 
  unnest(c(result)) |> 
  group_by(name) |> 
  mutate(
    index = row_number()
  )

observed_long |> 
  ggplot(aes(x = index, y = result, group = name)) +
  geom_line(color = "grey") +
  geom_point(aes(color = result)) +
  scale_color_brewer(type = "qual") +
  facet_grid(rows = vars(name)) +
  labs(
    title = "Sequences of coin flips",
    subtitle = "Only one sequence was generated from fair and dependent coin flips",
    caption = "Each sequence consists of 200 results, either 'heads' or 'tails'"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

::: callout-warning
## Spoilers ahead

Over the course of the next several sections, we will gradually eliminate options sequence by sequence.
:::

## A first approach: eye-balling it

Staring at the sequences, I notice a couple things at first:

-   `A` always alternates between heads and tails, on every single flip
-   `E` stays heads for a long time, then switches to tails for a long time, and then the cycle repeats
-   All of the other cycles switch back and forth between heads and tails fairly often, with some long streaks of all heads or all tails as well

Immediately I think I can rule out `A` and `E`, because each flip appears to depend on the previous flips, and this shouldn't happen when I repeatedly flip a fair coin. Hopefully, I can develop a test later on that will capture this intuition more quantitatively, but for now, I just rule out `A` and `E`.

There are some other patterns that look suspicious to me, but I've previously learned that my intuition about which sequences are random and which aren't isn't very good. Part of the challenge here is that I am mainly looking at non-random sequences in @fig-observed, and this doesn't tell me very much about which patterns are surprising under a random model. So next I generate six sequences by repeatedly flipping a fair coin. In light of these fair sequences, I can't really eye-ball anything else that looks suspicious in the true sequences.

```{r}
#| label: fig-fair
#| column: body-outset
set.seed(27)

sample_independent_fair_sequence <- function() {
  outcomes <- c("H", "T")
  sample(outcomes, size = 200, replace = TRUE)
}

num_samples <- 6

long_fair <- tibble(
  result = map(1:num_samples, \(x) sample_independent_fair_sequence())
) |> 
  mutate(
    name = glue("Fair {LETTERS[1:num_samples]}")
  ) |> 
  unnest(c(result)) |> 
  group_by(name) |> 
  mutate(
    index = row_number()
  )

long_fair |> 
  ggplot(aes(x = index, y = result, group = name)) +
  geom_line(color = "grey") +
  geom_point(aes(color = result)) +
  scale_color_brewer(type = "qual") +
  facet_grid(rows = vars(name)) +
  labs(
    title = "Sequences of coin flips",
    subtitle = "Every sequence was generated generated from fair and dependent coin flips",
    caption = "Each sequence consists of 200 results, either 'heads' or 'tails'"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

## A second approach: checking if the coin is fair

The next thing that comes to mind is that, if a coin is fair, then roughly half the flips should be heads and half should be tails. Since I know how to simulate sequences of repeatedly flipped fair coins, I'll generate a bunch of sequences from this null model, and then compare the number of heads in the observed sequences to the number of heads in the simulated sequences.

```{r}
#| column: body-outset
count_heads <- function(results) {
  sum(results == "H")
}

sample_one_test_statistic <- function(test_statistic) {
  results <- sample_independent_fair_sequence()
  test_statistic(results)
}

sample_fair_independent_statistic <- function(test_statistic, num_samples = 1000) {
  map_dbl(1:num_samples, \(x) sample_one_test_statistic(test_statistic))
}

test_statistics <- list(
  "Num heads" = count_heads
)

statistics_df <- test_statistics |> 
  enframe(name = "statistic_name", value = "test_statistic")

null_distributions <- statistics_df |> 
  mutate(
    null_statistic = map(test_statistic, sample_fair_independent_statistic),
  ) |> 
  select(-test_statistic) 

null_distributions_long <- null_distributions |>
  unnest(c(null_statistic))

observed_statistics <- observed_nested |> 
  select(-sequence) |> 
  expand_grid(statistics_df) |> 
  mutate(
    statistic = map2_dbl(
      result, test_statistic, 
      \(data, compute_statistic) compute_statistic(data)
    )
  ) |> 
  select(
    name, statistic_name, statistic
  )

# add rejection region next

null_distributions_long |> 
  ggplot(aes(x = null_statistic)) +
  geom_histogram(binwidth = 1, center = 0) +
  geom_vline(
    data = observed_statistics,
    aes(color = name, xintercept = statistic)
  ) +
  facet_wrap(
    vars(name),
    scales = "free",
    nrow = 1
  ) +
  scale_color_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(80, 100, 120)) +
  labs(
    title = "Number of heads in each sequence",
    subtitle = "c.f. number of heads in random sequences (grey)"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

:::{.callout-important}
### Test statistic close to its expectation

TODO: this doesn't work

:::

```{r}
null_distributions |> 
  left_join(
    observed_statistics,
    by = "statistic_name",
    multiple = "all"
  ) |> 
  mutate(
    expected = map_dbl(null_statistic, mean),
    observed_quantile = map2_dbl(null_statistic, statistic, \(ns, s) ecdf(ns)(s)),
    p_value = pmin(observed_quantile, 1 - observed_quantile)
  ) |> 
  select(-statistic_name, -null_statistic)
```

note: direction of the test is a little challenging to get right a priori. some comments on why you might not want to specify the direction of the test ahead of time later on.

:::{.callout-important}
### Test statistic with largest empirical p-value

TODO: this doesn't work

:::

The typical way to do this is by computing








highest p-value does not imply most likely hypothesis test statistic closest to expected value of test statistic does not imply most likely hypothesis

data can be compatible with many hypotheses simultaneously -- this is not even problem here since the null hypothesis is a point-set!

```{r}
lengths_of_head_sequences <- function(results) {
  rle_encoded <- rle(results)
  head_sequence_indicators <- rle_encoded$values == "H"
  
  if (!any(head_sequence_indicators)) {
    warning("No head sequences!")
    return(NA)
  }
  
  rle_encoded$lengths[head_sequence_indicators]
}

longest_heads_subsequence <- function(results) {
  max(lengths_of_head_sequences(results))
}

shortest_heads_subsequence <- function(results) {
  min(lengths_of_head_sequences(results))
}

```

```{r}

test_statistics <- list(
  "Longest head seq" = longest_heads_subsequence
)

statistics_df <- test_statistics |> 
  enframe(name = "statistic_name", value = "test_statistic")

null_distributions <- statistics_df |> 
  mutate(
    null_statistic = map(test_statistic, sample_fair_independent_statistic),
  ) |> 
  select(-test_statistic) 

null_distributions_long <- null_distributions |>
  unnest(c(null_statistic))

observed_statistics <- observed_nested |> 
  select(-sequence) |> 
  expand_grid(statistics_df) |> 
  mutate(
    statistic = map2_dbl(
      result, test_statistic, 
      \(data, compute_statistic) compute_statistic(data)
    )
  ) |> 
  select(
    name, statistic_name, statistic
  )

# add rejection region next

null_distributions_long |> 
  ggplot(aes(x = null_statistic)) +
  geom_histogram(binwidth = 1, center = 0) +
  geom_vline(
    data = observed_statistics,
    aes(color = name, xintercept = statistic)
  ) +
  facet_wrap(
    vars(name),
    scales = "free",
    nrow = 1
  ) +
  scale_color_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(80, 100, 120)) +
  labs(
    title = "Number of heads in each sequence",
    subtitle = "c.f. number of heads in random sequences (grey)"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

```{r}
num_islands <- function(results) {
  rle_encoded <- rle(results)
  sum(table(rle_encoded$lengths))
}

matches <- function(results) {
  sum(results == dplyr::lag(results), na.rm = TRUE)
}


test_statistics <- list(
  "Num islands" = num_islands,
  "Matches" = matches
)

statistics_df <- test_statistics |> 
  enframe(name = "statistic_name", value = "test_statistic")

null_distributions <- statistics_df |> 
  mutate(
    null_statistic = map(test_statistic, sample_fair_independent_statistic),
  ) |> 
  select(-test_statistic) 

null_distributions_long <- null_distributions |>
  unnest(c(null_statistic))

observed_statistics <- observed_nested |> 
  select(-sequence) |> 
  expand_grid(statistics_df) |> 
  mutate(
    statistic = map2_dbl(
      result, test_statistic, 
      \(data, compute_statistic) compute_statistic(data)
    )
  ) |> 
  select(
    name, statistic_name, statistic
  )

# add rejection region next

null_distributions_long |> 
  ggplot(aes(x = null_statistic)) +
  geom_histogram(binwidth = 1, center = 0) +
  geom_vline(
    data = observed_statistics,
    aes(color = name, xintercept = statistic)
  ) +
  facet_wrap(
    vars(name),
    scales = "free",
    nrow = 1
  ) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Number of heads in each sequence",
    subtitle = "c.f. number of heads in random sequences (grey)"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```


sometime framed as: cannot "accept" the null hypothesis, can only reject it

p-hacking. eye-balling stuff is dangerous, need to think about properties of random samples and test statistics from those things, not so much about the properties of data you actually have.

> I found out that the probability of "HHHHHHTTTTTT" occurring 1 or more times in 200 flips is smaller than 0.05, so I decided to eliminate flips4. So we now have flips2 and flips3 left.


```{r}
# HTHHHHHHTTTTTTHHHTTHTHHHHTTTH
# HHHHHHTTTTTT
num_subseq <- function(results, subseq = "HTHHHHHHTTTTTTHHHTTHTHHHHTTTH") {
  collapsed <- paste0(results, collapse = "")
  str_count(collapsed, subseq)
}

test_statistics <- list(
  "Num subseq" = num_subseq
)

statistics_df <- test_statistics |> 
  enframe(name = "statistic_name", value = "test_statistic")

null_distributions <- statistics_df |> 
  mutate(
    null_statistic = map(test_statistic, sample_fair_independent_statistic),
  ) |> 
  select(-test_statistic) 

null_distributions_long <- null_distributions |>
  unnest(c(null_statistic))

observed_statistics <- observed_nested |> 
  select(-sequence) |> 
  expand_grid(statistics_df) |> 
  mutate(
    statistic = map2_dbl(
      result, test_statistic, 
      \(data, compute_statistic) compute_statistic(data)
    )
  ) |> 
  select(
    name, statistic_name, statistic
  )

# add rejection region next

null_distributions_long |> 
  ggplot(aes(x = null_statistic)) +
  geom_histogram(binwidth = 1, center = 0) +
  geom_vline(
    data = observed_statistics,
    aes(color = name, xintercept = statistic)
  ) +
  facet_wrap(
    vars(name),
    scales = "free",
    nrow = 1
  ) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Number of heads in each sequence",
    subtitle = "c.f. number of heads in random sequences (grey)"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```


all data has surprising variation. looking at it, seeing something surprising, and then testing if that variation is surprising can lead you astray. this is called p-hacking.

> Since p-value is the probability that we see our data given that the null is true we want the flip data that has the highest p-value.

permutation tests don't work since they condition on the number of heads and tails, which is probably a bad idea

density of each sequence is exactly identical

why you can't use tests like likelihood ratios to order likelihood of null hypotheses

matches test statistic: how often do i and i+1st entries agree

obviously 1 and 5 have dependence -- this is good! test should reject these ones!

come up with a test that rejects every single sequence

HH HT TH and TT histograms

number of runs / islands of constancy

singleton count / isolated singleton, not sum of heads in a sequence Wald-Wolfowitz test / statistic

p-hacking by picking a random test statistic from each sequence

## Follow up challenges

- multiple testing (family-wise error rate of independent and even dependent tests)
- composite null hypothesis


