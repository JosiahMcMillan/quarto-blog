---
title: "hypothesis testing nuances, by example"
subtitle: |
  todo
date: "2022-10-20"
categories: [hypothesis testing, frequentism, p-hacking]
draft: true
echo: false
fig-width: 10
fig-height: 6
---

**TL; DR**: We develop a hypothesis test to determine if a sequence of the coin flips comes from repeatedly flipping a fair coin. In the process, we discover lots of things that can go wrong.

So here's a homework problem that we recently gave out in an undergrad data science course. Suppose you have the following six sequences of coin flips. Exactly one sequence is generated by repeatedly flipping a fair coin. Which sequence is it?

```{r}
#| echo: true

sequences <- c(
  A = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHTHTHTHHTTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHTTHTHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTHTHTHTHTHTHTHTHHTHTHTHTH",
  B = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT",
  C = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH",
  D = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH",
  E = "HHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTHHHHHHHHTTTTTTTHHHHHHHHHTTTTTTTTTHHHHHHHHTTTHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHTTTTTTTTTTTHHHHHHHHHHHHHTTTTTTTTTTHH",
  F = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"
)
```

::: callout-important
## Recommendation

Try to solve this problem on your own before reading on!
:::

To make the problem a little more concrete, here's a visualization of the coin flip sequences. Which one looks genuinely random to you?

```{r}
#| label: fig-observed
#| fig-cap: TOOD
#| message: false
#| warning: false
#| column: body-outset
library(tidyverse)
library(glue)

theme_set(theme_classic(16))

observed_nested <- tibble(
  name = glue("Seq {LETTERS[1:6]}"),
  sequence = sequences
) |> 
  mutate(
    result = str_split(sequence, "")
  )

observed_long <- observed_nested  |> 
  select(-sequence) |> 
  unnest(c(result)) |> 
  group_by(name) |> 
  mutate(
    index = row_number()
  )

observed_long |> 
  ggplot(aes(x = index, y = result, group = name)) +
  geom_line(color = "grey") +
  geom_point(aes(color = result)) +
  scale_color_brewer(type = "qual") +
  facet_grid(rows = vars(name)) +
  labs(
    title = "Sequences of coin flips",
    subtitle = "Only one sequence was generated from fair and dependent coin flips",
    caption = "Each sequence consists of 200 results, either 'heads' or 'tails'"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

::: callout-warning
## Spoilers ahead

Over the course of the next several sections, we will gradually eliminate options sequence by sequence.
:::

## A first approach: eye-balling it

Staring at the sequences, I notice a couple things at first:

-   `A` always alternates between heads and tails, on every single flip
-   `E` stays heads for a long time, then switches to tails for a long time, and then the cycle repeats
-   All of the other cycles switch back and forth between heads and tails fairly often, with some long streaks of all heads or all tails as well

Immediately I think I can rule out `A` and `E`, because each flip appears to depend on the previous flips, and this shouldn't happen when I repeatedly flip a fair coin. Hopefully, I can develop a test later on that will capture this intuition more quantitatively, but for now, I just rule out `A` and `E`.

There are some other patterns that look suspicious to me, but I've previously learned that my intuition about which sequences are random and which aren't isn't very good. Part of the challenge here is that I am mainly looking at non-random sequences in @fig-observed, and this doesn't tell me very much about which patterns are surprising under a random model. So next I generate six sequences by repeatedly flipping a fair coin (from this point onward, when I refer to a "random sequence", I mean sequence of heads and tails generated by repeatedly flipping a fair coin just like this).

```{r}
#| label: fig-fair
#| column: body-outset
set.seed(27)

sample_sequence <- function() {
  outcomes <- c("H", "T")
  sample(outcomes, size = 200, replace = TRUE)
}

num_samples <- 6

long_fair <- tibble(
  result = map(1:num_samples, \(x) sample_sequence())
) |> 
  mutate(
    name = glue("Fair {LETTERS[1:num_samples]}")
  ) |> 
  unnest(c(result)) |> 
  group_by(name) |> 
  mutate(
    index = row_number()
  )

long_fair |> 
  ggplot(aes(x = index, y = result, group = name)) +
  geom_line(color = "grey") +
  geom_point(aes(color = result)) +
  scale_color_brewer(type = "qual") +
  facet_grid(rows = vars(name)) +
  labs(
    title = "Sequences of coin flips",
    subtitle = "Every sequence was generated generated from fair and dependent coin flips",
    caption = "Each sequence consists of 200 results, either 'heads' or 'tails'"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```

In light of these fair sequences, I can't really eye-ball anything else that looks suspicious.

## A second approach: checking if the coin is fair

The next thing that comes to mind is that, if a coin is fair, then roughly half the flips should be heads and half should be tails. Since I know how to simulate sequences of repeatedly flipped fair coins, I'll generate a bunch of sequences from this null model, and then compare the number of heads in the observed sequences to the number of heads in the simulated sequences.

```{r}
#| column: body-outset
count_heads <- function(results) {
  sum(results == "H")
}

sample_statistic_under_null <- function(test_statistic, num_samples = 1000) {
  map_dbl(1:num_samples, \(x) test_statistic(sample_sequence()))
}


null_distribution <- sample_statistic_under_null(count_heads)

observed_statistics <- observed_nested |> 
  mutate(
    statistic = map_dbl(result, count_heads)
  ) |> 
  select(name, statistic)

# add rejection region next
observed_statistics |> 
  mutate(
    null_sample = list(null_distribution)
  ) |> 
  unnest(c(null_sample)) |> 
  ggplot(aes(x = null_sample)) +
  geom_histogram(
    binwidth = 1,
    center = 0
  ) +
  geom_vline(aes(xintercept = statistic, color = name)) +
  facet_wrap(
    vars(name),
    scales = "free",
    nrow = 1
  ) +
  scale_color_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(80, 100, 120)) +
  labs(
    title = "Number of heads in each sequence",
    subtitle = "compare to number of heads in random sequences (grey)"
  ) +
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )

quantile(null_distribution, c(0.05, 0.95))
```

By looking at the grey histogram (which is repeated in each panel), I can observed that, in ninety percent of the sequences from a repeatedly flipped fair coin, the number of heads in the sequence is between the fifth percentile \$q\_{0.05} = \$ `r quantile(null_distribution, 0.05)` and the ninety-fifth percentile \$q\_{0.95} = \$ `r quantile(null_distribution, 0.95)`. This means that it is *unlikely* that I will see less than `r quantile(null_distribution, 0.05)` heads or more than `r quantile(null_distribution, 0.95)` heads in a random sequence.

```{r}
library(gt)

head_count_stats <- observed_statistics |> 
  mutate(
    expected = mean(null_distribution),
    observed_quantile = map_dbl(statistic, \(stat) ecdf(null_distribution)(stat)),
    p_value = pmin(observed_quantile, 1 - observed_quantile)
  )

head_count_stats |> 
  select(name, statistic) |> 
  gt() |> 
  cols_label(
    name = "Sequence",
    statistic = "Heads in sequence"
  )
```

Since sequence F has only 70 heads, it seems unlikely that sequence F comes from the null model of independent, fair coin flips.

The approach that I have demonstrated above is to compute a *rejection region* for a test statistic that contains my test statistic $90%$ of the time under the null model. This is not the only way to approach the problem. I could also ask, for each sequence, how often do I see a larger number of heads in random sequences. This is known as computing a *p-value*.

```{r}
head_count_stats |> 
  select(name, p_value) |> 
  gt() |> 
  cols_label(
    name = "Sequence",
    p_value = "P-value"
  )
```

When the p-value is small, it means that the number of observed heads in a sequence is either much higher or much lower than typically seen in random sequences. In particular, a p-value of $p$ (which should always be between zero and one) means that random sequences had as many heads as the mystery sequence only $p \cdot 100\%$ of the time.

More intuitively: small p-values indicate that data is not compatible with a given model. In this case, the very small p-value for sequence $F$ indicates that sequence $F$ is not compatible the random sequence model for coin flips. Sequences $A, B, C, D$ and to a less extent $E$ are all compatible with the random sequence model.

Now, you may be tempted to conclude that sequence $C$ is in fact most likely to be sampled from the random model since it has the highest p-value. The trick is that low p-values tell us that the data is unlikely to come from the null model.

 Here is where we run into a frequent misconception. 
 
 compare: 
 
 The trick is that low p-values tell us that the data is unlikely to come from the null model.
 
 The trick is that low p-values tell us that the observed value of the *test statistic* is unlikely to come from the null model.

Here I see that in sequences from the null model (i.e. sequences from a fair coin, flipped repeatedly)

::: callout-important
### Test statistic close to its expectation

TODO: this doesn't work
:::

```{r}

```

note: direction of the test is a little challenging to get right a priori. some comments on why you might not want to specify the direction of the test ahead of time later on.

::: callout-important
### Test statistic with largest empirical p-value

TODO: this doesn't work
:::

The typical way to do this is by computing

highest p-value does not imply most likely hypothesis test statistic closest to expected value of test statistic does not imply most likely hypothesis

data can be compatible with many hypotheses simultaneously -- this is not even problem here since the null hypothesis is a point-set!

```{r}
lengths_of_head_sequences <- function(results) {
  rle_encoded <- rle(results)
  head_sequence_indicators <- rle_encoded$values == "H"
  
  if (!any(head_sequence_indicators)) {
    warning("No head sequences!")
    return(NA)
  }
  
  rle_encoded$lengths[head_sequence_indicators]
}

longest_heads_subsequence <- function(results) {
  max(lengths_of_head_sequences(results))
}

shortest_heads_subsequence <- function(results) {
  min(lengths_of_head_sequences(results))
}

```


```{r}
num_islands <- function(results) {
  rle_encoded <- rle(results)
  sum(table(rle_encoded$lengths))
}

matches <- function(results) {
  sum(results == dplyr::lag(results), na.rm = TRUE)
}
```

sometime framed as: cannot "accept" the null hypothesis, can only reject it

p-hacking. eye-balling stuff is dangerous, need to think about properties of random samples and test statistics from those things, not so much about the properties of data you actually have.

> I found out that the probability of "HHHHHHTTTTTT" occurring 1 or more times in 200 flips is smaller than 0.05, so I decided to eliminate flips4. So we now have flips2 and flips3 left.

```{r}
# HTHHHHHHTTTTTTHHHTTHTHHHHTTTH
# HHHHHHTTTTTT
num_subseq <- function(results, subseq = "HTHHHHHHTTTTTTHHHTTHTHHHHTTTH") {
  collapsed <- paste0(results, collapse = "")
  str_count(collapsed, subseq)
}

test_statistics <- list(
  "Num subseq" = num_subseq
)
```

all data has surprising variation. looking at it, seeing something surprising, and then testing if that variation is surprising can lead you astray. this is called p-hacking.

> Since p-value is the probability that we see our data given that the null is true we want the flip data that has the highest p-value.

permutation tests don't work since they condition on the number of heads and tails, which is probably a bad idea

density of each sequence is exactly identical

why you can't use tests like likelihood ratios to order likelihood of null hypotheses

matches test statistic: how often do i and i+1st entries agree

obviously 1 and 5 have dependence -- this is good! test should reject these ones!

come up with a test that rejects every single sequence

HH HT TH and TT histograms

number of runs / islands of constancy

singleton count / isolated singleton, not sum of heads in a sequence Wald-Wolfowitz test / statistic

p-hacking by picking a random test statistic from each sequence

## Follow up challenges

-   multiple testing (family-wise error rate of independent and even dependent tests)
-   composite null hypothesis
