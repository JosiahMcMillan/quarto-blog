<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.257">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Hayes">
<meta name="dcterms.date" content="2019-07-26">

<title>alex hayes - an annotated bibliography on stochastic blockmodels</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-G6PQFW2XSK"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-G6PQFW2XSK', { 'anonymize_ip': true});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="alex hayes - an annotated bibliography on stochastic blockmodels">
<meta property="og:site-name" content="alex hayes">
<meta name="twitter:title" content="alex hayes - an annotated bibliography on stochastic blockmodels">
<meta name="twitter:creator" content="@alexpghayes">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">alex hayes</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">about</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html">posts</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../papers/index.html">papers</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../code/index.html">code</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching/index.html">teaching</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../talks/index.html">talks</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/alexpghayes"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/alexpghayes"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">an annotated bibliography on stochastic blockmodels</h1>
            <p class="subtitle lead"></p><p>some pointers to papers that were helpful when i got started in spectral network analysis, a woefully incomplete list</p><p></p>
                          <div class="quarto-categories">
                <div class="quarto-category">notes to self</div>
                <div class="quarto-category">networks</div>
                <div class="quarto-category">research</div>
              </div>
                  </div>
  </div>
    
  



  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Alex Hayes <a href="https://orcid.org/0000-0002-4985-5160" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2019-07-26</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a>
  <ul class="collapse">
  <li><a href="#other-network-models" id="toc-other-network-models" class="nav-link" data-scroll-target="#other-network-models">Other network models</a></li>
  </ul></li>
  <li><a href="#estimators-for-sbms" id="toc-estimators-for-sbms" class="nav-link" data-scroll-target="#estimators-for-sbms">Estimators for SBMs</a></li>
  <li><a href="#the-triangle-trick" id="toc-the-triangle-trick" class="nav-link" data-scroll-target="#the-triangle-trick">The triangle trick</a></li>
  <li><a href="#briefly-contagion" id="toc-briefly-contagion" class="nav-link" data-scroll-target="#briefly-contagion">Briefly, contagion</a></li>
  <li><a href="#the-end" id="toc-the-end" class="nav-link" data-scroll-target="#the-end">The end</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/alexpghayes/quarto-blog/edit/main/post/2019-07-26_an-annotated-bibliography-on-stochastic-blockmodels/index.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/alexpghayes/quarto-blog/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>I’ve been reading a lot of papers on network analysis recently. I thought I’d write down some takeaways and point out papers that I’ve found helpful. This collection of papers is centered around the stochastic blockmodel, and is intended to be introductory rather than comprehensive. I’ve included a few papers with other miscellaneous tidbits of interest.</p>
</section>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>The most basic random graph model is the Erdos-Renyi graph, which assumes that you have a fixed number of nodes, and edges appear independently with probability <span class="math inline">\(p\)</span>. The Erdos-Renyi model has been studied to death and there are tons of interesting papers you can read about it. In particular, the graph structure goes through a number of phrase transitions as <span class="math inline">\(p\)</span> varies. I’m pretty sure there’s a nice paper on this by Fan Chung but I can’t find the reference at the moment.</p>
<p>However, the Erdos-Renyi graph is pretty unrealistic and doesn’t look anything like real world graphs. The stochastic blockmodel (SBM) represents a first pass at a more plausible real world graph. In the SBM, we assume that each node belongs to one of <span class="math inline">\(k\)</span> communities. We then assume connections occur independently with probabilities that depend only on the communities of the nodes.</p>
<p>One major issue with SBMs is that they assume a uniform degree distribution, but real world graphs have highly skewed degree distributions. <span class="citation" data-cites="karrer_stochastic_2011">Karrer and Newman (<a href="#ref-karrer_stochastic_2011" role="doc-biblioref">2011</a>)</span> propose the degree-corrected SBM as a remedy to this problem. The paper additionally contains an interesting information-theoretic interpretation of modularity scores.</p>
<p>It also presents one standard (but unappealing) approach for fitting SBMs: (1) assign every node a community at random, (2) swap community labels at random, keeping the community assignments that result in the highest likelihood, and (3) do this a bunch of times because it’s random and you don’t want to get stuck in a local maximum. This is heuristic way to maximize the likelihood, which we should note is a <em>hard</em> problem here. Likelihood maximization requires optimizing over an <span class="math inline">\(n \times k\)</span> binary matrix, where <span class="math inline">\(n\)</span> is the number of nodes and <span class="math inline">\(k\)</span> is the number of communities. This is very non-convex.</p>
<p>Another key extension of the SBM comes in the form of the mixed membership SBM of <span class="citation" data-cites="airoldi_mixed_2008">Airoldi et al. (<a href="#ref-airoldi_mixed_2008" role="doc-biblioref">2008</a>)</span>. Instead of assigning each node to a single cluster, the mixed membership SBM allows soft community assignments, where each node can belong to different communities, with total memberships summing up to one. The paper makes an argument for this model based on heterogeneous degrees (it came out before the degree corrected SBM paper) that I didn’t find terribly convincing (to be fair, I also only skimmed it), but it’s easy to add degree correction to the mixed membership SBM, and I would consider the degree corrected mixed membership SBM as a good starting point in many circumstances. The paper also discusses selecting the number of communities <span class="math inline">\(k\)</span> via cross-validation and BIC, and introduces a variational Bayes estimator.</p>
<p>Personally I am not a huge fan of variational Bayes, so I didn’t read the details about the estimation procedure. In practice, if you use <a href="https://graph-tool.skewed.de/"><code>graph-tool</code></a>, one of the standard Python libraries to fit this sort of thing, I’m fairly sure you get variational Bayes estimates. Finally, the high resolution graphics in the PDF version of this paper caused my printer to shit a brick.</p>
<p>Another interesting extension of the SBM (that can also be degree corrected!) is the overlapping SBM of <span class="citation" data-cites="latouche_overlapping_2011">Latouche, Birmelé, and Ambroise (<a href="#ref-latouche_overlapping_2011" role="doc-biblioref">2011</a>)</span>. The overlapping SBM respects multiple community memberships better than the mixed SBM, but the finer details are somewhat lost on me. The paper has an interesting identifiability proof that went way over my mind but that I’d refer back to in the future if I ever wanted to do something similar. The paper also proposes a variational estimator, and then it compares the performance of the overlapping SBM with the mixed SBM on a network of French political blogs. It turns out the overlapping SBM does a little better than the mixed SBM, but they seem to be generally have comparable performance. The data analysis does a great job highlighting that sometimes you just get a trash cluster of nodes that don’t belong in any of the other, more meaningful clusters.</p>
<p>One slightly weird thing about the SBM is that the model is typically parameterized as having Poisson edges (i.e.&nbsp;elements of the network adjacency matrix <span class="math inline">\(A_{ij}\)</span> are assumed to come from a Poisson(<span class="math inline">\(\lambda_{ij}\)</span>) distribution). The naive way to generate a sample from a SBM is to loop through every element of the adjacency matrix and sample a Poisson random variable for that element. This is <span class="math inline">\(O(n^2)\)</span>, which is ridiculous because most graphs are sparse. <span class="citation" data-cites="rohe_note_2017">Rohe et al. (<a href="#ref-rohe_note_2017" role="doc-biblioref">2017</a>)</span> presents an <span class="math inline">\(O(m)\)</span> sampling scheme for random dot product graphs (a generalization of SBMs), where <span class="math inline">\(m\)</span> is the number of edges in the graph. I’m currently working on cleaning up the original code for this into an <a href="https://github.com/RoheLab/fastRG/">R package</a>.</p>
<p>Reading Karl’s paper helped me connect my “edge probabilities depend on communities” understanding of SBMs to the matrix-notation Poisson formulation of SBMs. The gist is that the Poisson distribution is completely determined by <span class="math inline">\(\lambda\)</span>, which is also the mean of a Poisson distribution, so writing down the expected value of an adjacency matrix is enough to completely determine an SBM. This matrix also has some nice structure and can be expressed as <span class="math inline">\(\mathbb{E} (A) = X B X^T\)</span> in the undirected case, where <span class="math inline">\(X\)</span> is binary, <span class="math inline">\(n \times k\)</span> and encodes community membership, and <span class="math inline">\(B\)</span> is <span class="math inline">\(k \times k\)</span> and encodes probabilities of connections between communities.</p>
<p>I’m fairly sure all of the papers so far mostly deal with undirected graphs (at least in the main exposition), and it’s a bit harder to think about a directed variant of the SBM. Now you have to imagine communities based on incoming edges, and communities based on outgoing edges. <span class="citation" data-cites="rohe_co-clustering_2016">Rohe, Qin, and Yu (<a href="#ref-rohe_co-clustering_2016" role="doc-biblioref">2016</a>)</span> present a directional version of the SBM and fit it using regularized spectral clustering. They also introduce an asymmetry score for nodes that can detect when incoming edges typically come from a different community than outgoing edges typically head to.</p>
<p>Regularized spectral clustering is definitely something you want to read about at some point; <span class="citation" data-cites="qin_regularized_2013">Qin and Rohe (<a href="#ref-qin_regularized_2013" role="doc-biblioref">2013</a>)</span> is a good reference. One thing that I’ve been struggling with is the connection between the eigendecomposition of a graph and graph properties that actually make sense to me (things like betweenness, degree, etc). A key connection here comes in the form of Cheeger’s ineuqality, which connects eigenvalues of the graph Laplacian (more on this in a moment) with graph conductance.</p>
<p>Some other interesting extensions to the SBM come in the form of the bipartite SBM (<span class="citation" data-cites="larremore_efficiently_2014">Larremore, Clauset, and Jacobs (<a href="#ref-larremore_efficiently_2014" role="doc-biblioref">2014</a>)</span>) and the high dimensional SBM (<span class="citation" data-cites="rohe_highest_2012">Rohe, Qin, and Fan (<a href="#ref-rohe_highest_2012" role="doc-biblioref">2012</a>)</span>). Both of these models are SBMs with structural parameters set to zero. The bipartite SBM seems like a good idea; Karl has told me the estimator proposed in <span class="citation" data-cites="rohe_highest_2012">Rohe, Qin, and Fan (<a href="#ref-rohe_highest_2012" role="doc-biblioref">2012</a>)</span> doesn’t really work.</p>
<section id="other-network-models" class="level3">
<h3 class="anchored" data-anchor-id="other-network-models">Other network models</h3>
<p><span class="citation" data-cites="gerlach_network_2018">Gerlach, Peixoto, and Altmann (<a href="#ref-gerlach_network_2018" role="doc-biblioref">2018</a>)</span> make interesting connections between SBMs and Latent Dirichlet Allocation. Another part of the network analysis universe deals with Exponential Random Graph Models (ERGMs). Personally I find ERGM parameters totally uninterpretable and the software difficult to use so I haven’t dug into them much and don’t really plan to.</p>
</section>
</section>
<section id="estimators-for-sbms" class="level2">
<h2 class="anchored" data-anchor-id="estimators-for-sbms">Estimators for SBMs</h2>
<p>While I feel like I’ve finally wrapped by head around the various SBM generative models, I am much less certain how to fit the bloody things. <span class="citation" data-cites="ghasemian_evaluating_2018">Ghasemian, Hosseinmardi, and Clauset (<a href="#ref-ghasemian_evaluating_2018" role="doc-biblioref">2018</a>)</span> compares a large number of methods for community detection, the vast majority of which are estimators for SBMs. The takeaway seems to be that degree corrected mixed SBMs are the way to go (if you want to do inference, at least). I’m sure there are a bunch of wacky neural nets that do better on various prediction tasks, but I haven’t found those papers yet. Well, more accurately, I have found a ton of papers but I have no idea which ones are good and I don’t care enough about neural nets to read them closely and find out.</p>
<p>Anyway, a rough overview of fitting SBMs. There are a lot of ways to do it, and none of them is especially appealing. The naive approach is to get MLE estimates. The papers that I’ve seen do this use a “swap labels randomly and keep the highest likelihood” approach. I find this unsatisfying, and also confusing. I don’t get why people do this instead of throwing the problem into an industrial grade integer program solver like Gurobi<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. As a side note, I assume it’s much easier to optimize the likelihood of the mixed SBM, since group memberships live on simplices, which are convex, rather than lattices, which are not.</p>
<p>Then there’s a wide variety of Bayesian estimation approaches, many of which seem to be variational Bayes. Sure, I guess. I’m happy to use these if someone else implements them, and am happy to pick <span class="math inline">\(k\)</span> based on BIC from these models, but I’m trying to avoid learning anything about variational methods because then people might actually ask me to use them at some point. Also Bayes is slow.</p>
<p>Spectral methods form another very important category of estimators. Spectral here just means “based on an eigendecomposition or an SVD”. Undirected graphs have symmetric adjacency matrices, so you can do an eigendecomposition. Directed graphs might not be positive definite, so you have to do an SVD instead. Oftentimes spectral estimates are used to initialize variational fitting methods.</p>
<p>One important thing to note with spectral methods is that you don’t really want to use the raw adjacency matrix. The eigenvectors of the adjacency matrix localize on high degree nodes (<span class="citation" data-cites="martin_localization_2014">Martin, Zhang, and Newman (<a href="#ref-martin_localization_2014" role="doc-biblioref">2014</a>)</span>). So what people typically do is work with the degree normalized adjacency matrix, which is often called the graph Laplacian<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Using the graph Laplacian (often called <span class="math inline">\(\mathcal L\)</span>) like this instead of the adjacency matrix <span class="math inline">\(A\)</span> is sort of like moving from a basic SBM to a degree-corrected SBM. It turns out that the graph Laplacian has problems too, though. The eigenvectors of the graph Laplacian localize on low degree nodes (<span class="citation" data-cites="zhang_understanding_2018">Zhang and Rohe (<a href="#ref-zhang_understanding_2018" role="doc-biblioref">2018</a>)</span>). The solution to this is to use a <em>regularized</em> graph Laplacian. Fingers crossed I’ll post a short preprint containing some folk wisdom on regularization soonish.</p>
<p>Anyway, it turns out that running k-means on the eigenvectors of the regularized graph Laplacian is a decent way to estimate the node cluster memberships (<span class="citation" data-cites="qin_regularized_2013">Qin and Rohe (<a href="#ref-qin_regularized_2013" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="rohe_spectral_2011">Rohe, Chatterjee, and Yu (<a href="#ref-rohe_spectral_2011" role="doc-biblioref">2011</a>)</span>). For these spectral methods, one way to pick the number of communities is to look at the eigenvalues and use the elbow method. This is very heuristic but it works decently well. <span class="citation" data-cites="wang_dont_2016">Wang and Rohe (<a href="#ref-wang_dont_2016" role="doc-biblioref">2016</a>)</span> point out that getting the number of communities right isn’t terribly important, in a cleverly titled paper <em>Don’t mind the (eigen) gap</em>. You definitely don’t want to wildly overestimate <span class="math inline">\(k\)</span>, but if you cluster using <span class="math inline">\(k = 5\)</span> versus <span class="math inline">\(k = 10\)</span>, the resulting clusters typically tell a coherent story and don’t contradict each other in terms of substantive conclusions. In spectral land, and eigenvalue of zero corresponds to “this definitely isn’t a cluster”, so as long as you aren’t pushing <span class="math inline">\(k\)</span> up so high that <span class="math inline">\(\lambda_k \approx 0\)</span>, you’re probably fine. The intuition for this comes from the <span class="math inline">\(\mathbb E (A) = X B X^T\)</span> parameterization of the blockmodel.</p>
<p>Apparently there’s also some good minimum description length (MDL) approaches to selecting the number of communities, but I haven’t actually done any reading on this.</p>
<p>Some other spectral papers to know about include <span class="citation" data-cites="chaudhuri_spectral_2012">Chaudhuri, Chung, and Tsiatas (<a href="#ref-chaudhuri_spectral_2012" role="doc-biblioref">2012</a>)</span>, which explores a couple different forms of regularization, and <span class="citation" data-cites="chung_spectra_2003">Chung, Lu, and Vu (<a href="#ref-chung_spectra_2003" role="doc-biblioref">2003</a>)</span>, which discusses the distribution of eigenvalues of the adjacency matrix and the graph Laplacian.</p>
<p>A third category of estimators is based on graph thingajigs like betweenness. For example, the Girvan-Newman algorithm (<span class="citation" data-cites="newman_finding_2004">Newman and Girvan (<a href="#ref-newman_finding_2004" role="doc-biblioref">2004</a>)</span>) finds communities in graphs and I vaguely recall that it’s a consistent estimator for community assignments under some variant of the SBM<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. I could be wrong. Anyway, you typically run the algorithm for a bunch of different <span class="math inline">\(k\)</span> and then select <span class="math inline">\(k\)</span> based on a modularity score. The algorithm and modularity score are both based on computer science-y graph concepts, but it’s equivalent to MLE estimation sometimes (<span class="citation" data-cites="newman_equivalence_2016">Newman (<a href="#ref-newman_equivalence_2016" role="doc-biblioref">2016</a>)</span>). Anyway, Newman’s papers are generally great and you should just go read all of them<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
</section>
<section id="the-triangle-trick" class="level2">
<h2 class="anchored" data-anchor-id="the-triangle-trick">The triangle trick</h2>
<p>Another paper that I find particularly interesting is <span class="citation" data-cites="rohe_blessing_2013">Rohe and Qin (<a href="#ref-rohe_blessing_2013" role="doc-biblioref">2013</a>)</span>, both as a technical paper and as an insight into Karl’s psyche as he tries to start a religious cult based on network analysis. The gist of the paper is that there are lots of uninformative edges in sparse and transitive networks, and you can throw these edges out, keeping only the edges that participate in triangles.</p>
<p>You can do this really fast with some matrix algebra. Let <span class="math inline">\(A\)</span> be an adjacency matrix, and let <span class="math inline">\(A \odot B\)</span> be the elementwise product of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Then <span class="math inline">\(T = AA \odot A\)</span> is the matrix of triangles. That is, <span class="math inline">\(T_{ij}\)</span> is the number of triangles that both node <span class="math inline">\(i\)</span> and node <span class="math inline">\(j\)</span> participate in. You can then use <span class="math inline">\(T\)</span> just like you would normally use <span class="math inline">\(A\)</span>, and doing this cleans clusters up really nicely. You can do this with the (regularized) graph Laplacian as well. <span class="citation" data-cites="benson_higher-order_2016">Benson, Gleich, and Leskovec (<a href="#ref-benson_higher-order_2016" role="doc-biblioref">2016</a>)</span> is a followup that generalizes from the shared triangles matrix <span class="math inline">\(T\)</span> to the general case of shared motifs, which means “patterns that both node <span class="math inline">\(i\)</span> and node <span class="math inline">\(j\)</span> participate in.”</p>
</section>
<section id="briefly-contagion" class="level2">
<h2 class="anchored" data-anchor-id="briefly-contagion">Briefly, contagion</h2>
<p>Most of the reading I’ve been doing has been about SBMs, but there are some other papers that I highly recommend you read. The first is <span class="citation" data-cites="shalizi_homophily_2011">Shalizi and Thomas (<a href="#ref-shalizi_homophily_2011" role="doc-biblioref">2011</a>)</span>, which points out that social contagion is generally confounded in graphs where people are connected to people like themselves. The fancy phrase for this is <em>homophily</em>, and it happens in pretty much all interesting graphs. This is an important observation because there’s a huge literature on contagion models, some of which seems to aware of this result, and some of which doesn’t. One way to avoid homophily-contagion confounding is to run an experiment. <span class="citation" data-cites="taylor_randomized_2017">Taylor and Eckles (<a href="#ref-taylor_randomized_2017" role="doc-biblioref">2017</a>)</span> discusses how you might want to do this. In generally I think it’s worth reading some of the more sociological network papers with a healthy dose of skepticism.</p>
</section>
<section id="the-end" class="level2">
<h2 class="anchored" data-anchor-id="the-end">The end</h2>
<p>That’s it, that’s all I’ve got. Most of the papers I’ve linked to have great references, so if you get bored or this isn’t enough, you can always go down that rabbit hole.</p>
<p>I don’t have a good handle on what kinds of neural nets people are using for graph stuff thesedays, nor do I have a good handle on modern graph embeddings. If you read about and/or use that kind of stuff, please leave paper recommendations in the comments!</p>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-airoldi_mixed_2008" class="csl-entry" role="doc-biblioentry">
Airoldi, Edoardo M, David M Blei, Stephen E Fienberg, and Eric P Xing. 2008. <span>“Mixed <span>Membership</span> <span>Stochastic</span> <span>Blockmodels</span>,”</span> 34. <a href="http://jmlr.csail.mit.edu/papers/volume9/airoldi08a/airoldi08a.pdf">http://jmlr.csail.mit.edu/papers/volume9/airoldi08a/airoldi08a.pdf</a>.
</div>
<div id="ref-benson_higher-order_2016" class="csl-entry" role="doc-biblioentry">
Benson, A. R., D. F. Gleich, and J. Leskovec. 2016. <span>“Higher-Order Organization of Complex Networks.”</span> <em>Science</em> 353 (6295): 163–66. <a href="https://doi.org/10.1126/science.aad9029">https://doi.org/10.1126/science.aad9029</a>.
</div>
<div id="ref-chaudhuri_spectral_2012" class="csl-entry" role="doc-biblioentry">
Chaudhuri, Kamalika, Fan Chung, and Alexander Tsiatas. 2012. <span>“Spectral <span>Clustering</span> of <span>Graphs</span> with <span>General</span> <span>Degrees</span> in the <span>Extended</span> <span>Planted</span> <span>Partition</span> <span>Model</span>,”</span> 23. <a href="https://pdfs.semanticscholar.org/5ff3/9b3b89414c7f2305d2d5e2301404678bb067.pdf">https://pdfs.semanticscholar.org/5ff3/9b3b89414c7f2305d2d5e2301404678bb067.pdf</a>.
</div>
<div id="ref-chung_spectra_2003" class="csl-entry" role="doc-biblioentry">
Chung, F., L. Lu, and V. Vu. 2003. <span>“Spectra of Random Graphs with Given Expected Degrees.”</span> <em>Proceedings of the National Academy of Sciences</em> 100 (11): 6313–18. <a href="https://doi.org/10.1073/pnas.0937490100">https://doi.org/10.1073/pnas.0937490100</a>.
</div>
<div id="ref-gerlach_network_2018" class="csl-entry" role="doc-biblioentry">
Gerlach, Martin, Tiago P. Peixoto, and Eduardo G. Altmann. 2018. <span>“A Network Approach to Topic Models.”</span> <em>Science Advances</em> 4 (7): eaaq1360. <a href="https://doi.org/10.1126/sciadv.aaq1360">https://doi.org/10.1126/sciadv.aaq1360</a>.
</div>
<div id="ref-ghasemian_evaluating_2018" class="csl-entry" role="doc-biblioentry">
Ghasemian, Amir, Homa Hosseinmardi, and Aaron Clauset. 2018. <span>“Evaluating <span>Overfit</span> and <span>Underfit</span> in <span>Models</span> of <span>Network</span> <span>Community</span> <span>Structure</span>.”</span> <em>arXiv:1802.10582 [Physics, q-Bio, Stat]</em>, February. <a href="http://arxiv.org/abs/1802.10582">http://arxiv.org/abs/1802.10582</a>.
</div>
<div id="ref-karrer_stochastic_2011" class="csl-entry" role="doc-biblioentry">
Karrer, Brian, and M. E. J. Newman. 2011. <span>“Stochastic Blockmodels and Community Structure in Networks.”</span> <em>Physical Review E</em> 83 (1): 016107. <a href="https://doi.org/10.1103/PhysRevE.83.016107">https://doi.org/10.1103/PhysRevE.83.016107</a>.
</div>
<div id="ref-larremore_efficiently_2014" class="csl-entry" role="doc-biblioentry">
Larremore, Daniel B., Aaron Clauset, and Abigail Z. Jacobs. 2014. <span>“Efficiently Inferring Community Structure in Bipartite Networks.”</span> <em>Physical Review E</em> 90 (1): 012805. <a href="https://doi.org/10.1103/PhysRevE.90.012805">https://doi.org/10.1103/PhysRevE.90.012805</a>.
</div>
<div id="ref-latouche_overlapping_2011" class="csl-entry" role="doc-biblioentry">
Latouche, Pierre, Etienne Birmelé, and Christophe Ambroise. 2011. <span>“Overlapping Stochastic Block Models with Application to the <span>French</span> Political Blogosphere.”</span> <em>The Annals of Applied Statistics</em> 5 (1): 309–36. <a href="https://doi.org/10.1214/10-AOAS382">https://doi.org/10.1214/10-AOAS382</a>.
</div>
<div id="ref-martin_localization_2014" class="csl-entry" role="doc-biblioentry">
Martin, Travis, Xiao Zhang, and M. E. J. Newman. 2014. <span>“Localization and Centrality in Networks.”</span> <em>Physical Review E</em> 90 (5): 052808. <a href="https://doi.org/10.1103/PhysRevE.90.052808">https://doi.org/10.1103/PhysRevE.90.052808</a>.
</div>
<div id="ref-newman_equivalence_2016" class="csl-entry" role="doc-biblioentry">
Newman, M. E. J. 2016. <span>“Equivalence Between Modularity Optimization and Maximum Likelihood Methods for Community Detection.”</span> <em>Physical Review E</em> 94 (5): 052315. <a href="https://doi.org/10.1103/PhysRevE.94.052315">https://doi.org/10.1103/PhysRevE.94.052315</a>.
</div>
<div id="ref-newman_finding_2004" class="csl-entry" role="doc-biblioentry">
Newman, M. E. J., and M. Girvan. 2004. <span>“Finding and Evaluating Community Structure in Networks.”</span> <em>Physical Review E</em> 69 (2): 026113. <a href="https://doi.org/10.1103/PhysRevE.69.026113">https://doi.org/10.1103/PhysRevE.69.026113</a>.
</div>
<div id="ref-qin_regularized_2013" class="csl-entry" role="doc-biblioentry">
Qin, Tai, and Karl Rohe. 2013. <span>“Regularized <span>Spectral</span> <span>Clustering</span> Under the <span>Degree</span>-<span>Corrected</span> <span>Stochastic</span> <span>Blockmodel</span>.”</span> <em>arXiv:1309.4111 [Cs, Math, Stat]</em>, September. <a href="http://arxiv.org/abs/1309.4111">http://arxiv.org/abs/1309.4111</a>.
</div>
<div id="ref-rohe_spectral_2011" class="csl-entry" role="doc-biblioentry">
Rohe, Karl, Sourav Chatterjee, and Bin Yu. 2011. <span>“Spectral Clustering and the High-Dimensional Stochastic Blockmodel.”</span> <em>The Annals of Statistics</em> 39 (4): 1878–1915. <a href="https://doi.org/10.1214/11-AOS887">https://doi.org/10.1214/11-AOS887</a>.
</div>
<div id="ref-rohe_blessing_2013" class="csl-entry" role="doc-biblioentry">
Rohe, Karl, and Tai Qin. 2013. <span>“The Blessing of Transitivity in Sparse and Stochastic Networks.”</span> <em>arXiv:1307.2302 [Stat]</em>, July. <a href="http://arxiv.org/abs/1307.2302">http://arxiv.org/abs/1307.2302</a>.
</div>
<div id="ref-rohe_highest_2012" class="csl-entry" role="doc-biblioentry">
Rohe, Karl, Tai Qin, and Haoyang Fan. 2012. <span>“The <span>Highest</span> <span>Dimensional</span> <span>Stochastic</span> <span>Blockmodel</span> with a <span>Regularized</span> <span>Estimator</span>.”</span> <em>arXiv:1206.2380 [Math, Stat]</em>, June. <a href="http://arxiv.org/abs/1206.2380">http://arxiv.org/abs/1206.2380</a>.
</div>
<div id="ref-rohe_co-clustering_2016" class="csl-entry" role="doc-biblioentry">
Rohe, Karl, Tai Qin, and Bin Yu. 2016. <span>“Co-Clustering Directed Graphs to Discover Asymmetries and Directional Communities.”</span> <em>Proceedings of the National Academy of Sciences</em> 113 (45): 12679–84. <a href="https://doi.org/10.1073/pnas.1525793113">https://doi.org/10.1073/pnas.1525793113</a>.
</div>
<div id="ref-rohe_note_2017" class="csl-entry" role="doc-biblioentry">
Rohe, Karl, Jun Tao, Xintian Han, and Norbert Binkiewicz. 2017. <span>“A Note on Quickly Sampling a Sparse Matrix with Low Rank Expectation.”</span> <em>arXiv:1703.02998 [Stat]</em>, March. <a href="http://arxiv.org/abs/1703.02998">http://arxiv.org/abs/1703.02998</a>.
</div>
<div id="ref-shalizi_homophily_2011" class="csl-entry" role="doc-biblioentry">
Shalizi, Cosma Rohilla, and Andrew C. Thomas. 2011. <span>“Homophily and <span>Contagion</span> <span>Are</span> <span>Generically</span> <span>Confounded</span> in <span>Observational</span> <span>Social</span> <span>Network</span> <span>Studies</span>.”</span> <em>Sociological Methods &amp; Research</em> 40 (2): 211–39. <a href="https://doi.org/10.1177/0049124111404820">https://doi.org/10.1177/0049124111404820</a>.
</div>
<div id="ref-taylor_randomized_2017" class="csl-entry" role="doc-biblioentry">
Taylor, Sean J., and Dean Eckles. 2017. <span>“Randomized Experiments to Detect and Estimate Social Influence in Networks.”</span> <em>arXiv:1709.09636 [Physics, Stat]</em>, September. <a href="http://arxiv.org/abs/1709.09636">http://arxiv.org/abs/1709.09636</a>.
</div>
<div id="ref-wang_dont_2016" class="csl-entry" role="doc-biblioentry">
Wang, Song, and Karl Rohe. 2016. <span>“Don’t Mind the (Eigen) Gap,”</span> 7. <a href="http://www.stat.cmu.edu/~jiashun/Research/Selected/SCC-disc3.pdf">http://www.stat.cmu.edu/~jiashun/Research/Selected/SCC-disc3.pdf</a>.
</div>
<div id="ref-zhang_understanding_2018" class="csl-entry" role="doc-biblioentry">
Zhang, Yilin, and Karl Rohe. 2018. <span>“Understanding <span>Regularized</span> <span>Spectral</span> <span>Clustering</span> via <span>Graph</span> <span>Conductance</span>.”</span> <em>arXiv:1806.01468 [Cs, Stat]</em>, June. <a href="http://arxiv.org/abs/1806.01468">http://arxiv.org/abs/1806.01468</a>.
</div>
</div></section><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>I say this as someone who likes the idea of letting Gurobi solve all my problems for me, without ever having actually used Gurobi.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>There are a whole bunch of different but related things that get called the graph Laplacian. If you read a paper that mentions the graph Laplacian, be sure to read the definition.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a href="https://www.cs.rice.edu/~nakhleh/">Luay Nakhleh</a>, legendary Rice professor who teaches COMP 182, makes freshmen implement Girvan-Newman community detection in one of his homework assignments.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>I also really like papers by Dan Larremore, Elizaveta Levina, Aaron Clauset and Bin Yu.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/alexpghayes/quarto-blog">blog source</a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>