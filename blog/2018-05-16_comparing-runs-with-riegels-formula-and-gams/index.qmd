---
title: "comparing runs with riegel's formula and gams"
subtitle: "i've been looking for an excuse to play with gams forever"
date: "2018-05-16"
bibliography: comparing-runs-with-riegels-formula-and-gams.bib
execute:
  echo: false
  message: false
  warning: false
---

Runners often vary the distance and intensity of their workouts. In this post I demonstrate how to compare runs of different lengths using Riegel's formula. The formula accurately describes the trade-off between run distance and average speed for aerobic runs up to about a half-marathon in length. Using my Strava data, I demonstrate how to use Riegel's formula to measure the difficulty of runs on a standardized scale and briefly investigate how my fitness has changed over time with GAMs.

## Riegel's formula: a measure of running ability

@riegel proposed that aerobic exercise can be modeled via the power law equation:

$$t = a d^b$$

where $t$ is the time it takes to travel distance $d$. Here $a$ and $b$ are coefficients that depend on the activity (typically $a$ and $b$ are estimated separately for different ages and genders). $b = 1.06$ is a typical estimate for recreational runners, although $b$ might be as high as $1.08$ for elite runners. Using data from over two thousand runners, @vickers showed that this formula is well-calibrated for runs ranging from one mile to a half-marathon in length. For runs longer than a half marathon, the formula tends be too optimistic.

We can also reformulate the equation to deal with speed rather than time. Letting $b = 1 + k$ we have:

$$s = {d \over t} = {1 \over a d^k}$$

where $s$ is speed. We can also estimate the time it takes to complete a run of length $d_2$ given a run of length $d_1$ in time $t_1$ (it's typical to estimate a Riegel curve based on a single best effort[^1]): 

[^1]: Wouldn't it be better to calculate a Riegel curve based on several best efforts? Yes, but people who have multiple recent best times normally race enough that they don't need to estimate Riegel curves in the first place.

$$t_2 = t_1 \cdot \left(d_2 \over d_1 \right)^b$$

Similarly we can rearrange to calculate speed instead:

$$s_2 = s_1 \cdot \left(d_1 \over d_2 \right)^k$$

Using this equation for a set of distances, we can estimate a curve describing maximal speeds at each distance. For example, my best recent effort was a 5K that I completed in 18:52, which results in the following curve:

```{r}
library(tidyverse)
library(here)
library(lubridate)
library(mgcv)
library(gratia)
library(ggmap)

theme_set(theme_minimal(12))

b <- 1.07
k <- b - 1
miles_per_km <- 0.621371

hours <- function(min, sec) (min + sec / 60) / 60
speed_from_pace <- function(min, sec) 60 / (min + sec / 60)  # min/mile to mph

# time to complete a run of distance new_dist given run (dist/time)
riegel_time <- function(time, dist, new_dist = 5 * miles_per_km) {
  time * (new_dist / dist)^b
}

# riegel speed estimates for 3/4 miles to a marathon based on run (dist/time)
riegel_speed <- function(time, dist) {
  new_dist <- seq(0.75, 27, length.out = 200)
  speed <- (dist / time) * (dist / new_dist)^k
  tibble(dist = new_dist, speed = speed)
}

# Strava pace zones based on 18:52 5K PR

regions <- tribble(
  ~exercise_type, ~low, ~high,
  "anaerobic", speed_from_pace(5, 49), 25,
  "VO2 max", speed_from_pace(6, 11), speed_from_pace(5, 49),
  "threshold", speed_from_pace(6, 36), speed_from_pace(6, 11),
  "tempo", speed_from_pace(7, 22), speed_from_pace(6, 36),
  "endurance", speed_from_pace(8, 33), speed_from_pace(7, 22),
  "recovery", 0, speed_from_pace(8, 33)) %>% 
  mutate(exercise_type = forcats::fct_inorder(exercise_type))

speed_curve <- riegel_speed(hours(18, 52), 5 * miles_per_km)

ggplot() +
  geom_rect(data = regions,
            aes(xmin = -Inf, xmax = Inf,
                ymin = low, ymax = high, fill = exercise_type), alpha = 0.4) +
  scale_fill_brewer(type = "div") +
  coord_cartesian(ylim = c(6.5, 11)) +
  geom_line(data = speed_curve, aes(dist, speed), size = 1) +
  geom_vline(xintercept = c(1, 13.1), alpha = 0.7) +
  labs(title = "Riegel curve based on 5K in 18:52",
       subtitle = "Black line estimates maximal maintainable speed for given distance",
       y = "Speed (mph)",
       x = "Distance (miles)")
```

Notice the exponential decay in speed with run distance. This plot also includes a visualization of exercise types at various speeds[^2], using a rough categorization from Strava again based on the 5K effort. The takeaway is that exercise at different intensities and durations uses different muscular mechanisms. The vertical lines mark the region where Riegel's curve is well calibrated.

[^2]: If you're interested in this kind of stuff, check out [The Lore of Running](https://www.amazon.com/Lore-Running-4th-Timothy-Noakes/dp/0873229592) by Timothy Noakes.

Within the aerobic region, we can treat points on the Riegel curve as equally difficult. The entire Riegel curve serves as a measure of fitness, but we can describe the entire curve by choosing a single point to act as a reference. I choose to standardize my runs to their equivalent 5K times.

## Data

I record my runs using [Strava](https://www.strava.com). Strava can analyze data recorded on a number of devices, but I just run Strava directly on my phone. During a run, Strava records my latitude and longitude once per second. These measurements are typically accurate to within 10 meters. For this analysis I [bulk exported](https://support.strava.com/hc/en-us/articles/216918437-Exporting-your-Data-and-Bulk-Export) my Strava data.

In total I have recordings of 45 runs from November 2017 to April 2018[^3]. The trajectory of one of these runs is below:

[^3]: I stopped running in April after being proscribed Cipro for an infection. Cipro and other fluoroquinolone's have the side effect of [*spontaneous tendon rupture*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4080593/) for up to 6 months after use, although most of the risk is in the first month after usage. Achilles tendons are at the highest risk. If you run, ask to be put on another medication!

```{r fig.cap = "Run in black."}
runs <- read_rds(here::here("blog", "2018-05-16_comparing-runs-with-riegels-formula-and-gams", "2018-04-17-runs-alex.rds"))

r <- filter(runs, run == 42)

run_map <- function(run_df) {
  
  run_bbox <- c(
    left = min(run_df$lon),
    right = max(run_df$lon),
    bottom  = min(run_df$lat),
    top = max(run_df$lat)
  )
  
  get_stamenmap(run_bbox, zoom = 15, maptype = "watercolor") %>% 
    ggmap() + 
    geom_path(
      data = run_df,
      aes(lon, lat),
      size = 2,
      lineend = "round",
      color = "black"
    ) +
    theme_nothing()
}

run_map(r)
```

This is a fairly typical run of mine around Rice's outer loop[^4]. In addition to plotting individual runs, we can look at how my runs have evolved over time by visualizing some summary statistics for each run:

[^4]: Houston is totally flat so I ignore the effect of hills on my runs. If you live in a hilly place you probably want to use a grade adjusted speed. Here's a [post](https://medium.com/strava-engineering/improving-grade-adjusted-pace-b9a2a332a5dc) by the Strava team on calculating grade adjusted pace, although it's not enough to recreate their calculation. References to literature on an established way to do this appreciated.

```{r}
metrics <- runs %>% 
  mutate_at(vars(run), as.numeric) %>% 
  group_by(run) %>% 
  summarize(
    start = min(time),
    dist = sum(dx),
    time = sum(dt),
    speed = dist / time,
    pace = time / dist,
    riegel_5k_time = riegel_time(time, dist) * 60) %>%   # minutes
  mutate(t = as.numeric(start - min(start), "days"))     # days since first run

metric_names <- c(
  "time" = "Time (minutes)",
  "dist" = "Distance (miles)",
  "speed" = "Speed (mph)",
  "riegel_5k_time" = "Riegel 5K Time (minutes)"
)

metrics %>%
  mutate(time = time * 60) %>% 
  gather(metric, value, time, dist, speed, riegel_5k_time) %>% 
  ggplot(aes(start, value, color = metric)) +
  geom_point() +
  geom_smooth() +
  scale_color_viridis_d() +
  facet_wrap(~metric, scales = "free_y", labeller = as_labeller(metric_names)) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") +
  labs(title = "Runs over time")
```

## Changing fitness over time with GAMs

Now I use a Generalized Additive Model to understand how my fitness changes over time, following @simpson. Using `mgcv` I fit a model of the form:

$$\texttt{riegel_5k_time}_i = f(t_i) + \varepsilon_i \qquad \varepsilon_i \sim \mathrm{Normal}(0, \sigma^2)$$
where $t_i$ is the number of days since my first run and $f$ is a smooth function. I also fit a model of the same form but with additional continuous autoregressive (1) structure in case there is residual autocorrelation in the time series after fitting the model. 

Both models fit the data well, but the CAR(1) structure turns out to be unnecessary. We briefly inspect the original model:

```{r}
m1 <- gamm(riegel_5k_time ~ s(t), data = metrics)
m2 <- gamm(riegel_5k_time ~ s(t), data = metrics,
           correlation = corCAR1(form =  ~ t))

summary(m1$gam)
```

```{r}
#| eval: false

# check that models fit well. they do.
gam.check(m1$gam, rep = 100)
gam.check(m2$gam, rep = 100)

# compare models: no CAR(1) necessary
anova(m1$lme, m2$lme)
```

We also plot the fit model:

```{r}
new <- with(metrics, tibble(t = seq(min(t), max(t), length.out = 200)))
preds <- bind_cols(new, predict(m1$gam, new, type = "response", se.fit = TRUE)) %>% 
  mutate(lower = fit - 2 * se.fit,
         upper = fit + 2 * se.fit,
         time = duration(t, unit = "days") + min(metrics$start))

ggplot(preds, aes(x = time, y = fit)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, fill = "black") +
  geom_point(data = metrics, mapping = aes(x = start, y = riegel_5k_time),
             inherit.aes = FALSE) +
  geom_rug(data = metrics, mapping = aes(x = start),
             inherit.aes = FALSE) +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Riegel 5K Equivalent Running Times",
       subtitle = "GAM estimated mean overlaid",
       y = "Riegel 5K Time (minutes)") +
  theme(axis.title.x = element_blank())
```

My estimated fitness passes some sanity checks: (1) I lose fitness over winter break when I'm not working out, (2) toward the end of the spring semester after several months of training, I start to plateau. My fitness should probably be improving in November, when I was training fairly hard, but I had one spectacularly slow long run that that seems to be throwing the estimates off.

<!-- prediction intervals for a GAM: https://stat.ethz.ch/pipermail/r-help/2011-April/275632.html -->

What I'm really interested in here is how my fitness changes over time, or the derivative of my smoothed Riegel 5K times. To estimate this, we can draw simulations from the posterior of the GAM, and then approximate the derivative via finite differences. Gavin Simpson's wonderful [gratia](https://github.com/gavinsimpson/gratia) package provides this functionality, and we plot the first derivative of the GAM below:

```{r}
d <- fderiv(m1, newdata = new)

d_ci <- new %>% 
  mutate(time = duration(t, unit = "days") + min(metrics$start)) %>% 
  bind_cols(confint(d, type = "simultaneous", level = 0.95))

d_ci %>% 
  ggplot(aes(time, est)) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed") +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, fill = "black") +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Instantaneous change in Riegel 5K time",
       subtitle = "Simultaneous 95% CI represented as grey band",
       y = "Change in Mean Riegel 5K time (minutes/day)") +
  theme(axis.title.x = element_blank())
```

Here we see the same trends as before: losing fitness over winter break, big improvements in January, my first month of serious training, and a plateau towards the end of the semester. Interestingly, my changing in fitness level is never significant. This doesn't match with my perceived experience, and I attribute this again to measuring mean effort rather than maximal effort. I ran my recovery and long runs at about a 7:30 pace all semester, and really pushed myself only once in every three or four runs. So there's a lot of runs in there that make it look like I'm not doing much.

## Takeaways

Riegel's formula provides a nice way to standardize runs, and GAMs are a satisfying and interpretable way to investigate how run capacity changes over time. An interesting problem is to model best efforts rather than mean efforts. I'm brainstorming on this at the moment. In a future blog post I'll show how to efficiently process and tidy Strava GPX files. I'm also curious to replicate @vickers, or to repeat this analysis using Gaussian processes or state space models.

