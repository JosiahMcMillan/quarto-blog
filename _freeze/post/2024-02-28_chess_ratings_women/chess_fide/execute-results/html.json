{
  "hash": "a1d005453cefb165f105a5ddcaabeccd",
  "result": {
    "markdown": "---\ntitle: \"Chess Ratings and Gender gaps\"\nsubtitle: | \n  revisiting sampling bias\ndate: \"2024-02-28\"\ncategories: [chess, sampling, bias, simulation]\neditor: visual\ncache: true\ndf_print: tibble\nformat: html\n---\n\n\n<!-- \n\n---\ntitle: \"Chess Ratings and Gender gaps\"\neditor: visual\ncache: true\n--- -->\n\n\nSome have posited that there are differences between men and women which spring out of some genetic component somewhere deep in the chess parts of the brain that were responsible for early human victories over our greatest animal adversaries -- allowing us to stall for time with a friendly game of chess until members of our tribe could come spear our adversaries while played for a draw. Thus chess skill would necessarily be unevenly distributed among genders much as hunting was before our species settled down to enjoy some agriculture. Still others believe that chess has an issue with too few women playing which is what explains the majority of the gap between the performance at the highest levels of chess. Due to a lack of recorded games from prehistory, I instead seek to show this second explanation is sufficient for explaining this variation between the two genders in terms of performance.\n\n![Chess used to have higher stakes](./images/prehistoric_chess.webp)\n\n\n[Other authors](https://en.chessbase.com/post/what-gender-gap-in-chess) have discussed this topic somewhat at length and my code here is adapted from theirs, however my work here covers the whole universe of FIDE ratings rather than only the Indian ratings which should allow us to determine if this sampling variability explanation is merely an Indian phenomena or a broader phenomena.\n\nDue to Covid-19 impacting the number of chess competitions held I use 2019 data and take the average of every players standard ratings for the year to avoid some of the individual variability in ratings throughout the year, this also helps to keep more players in our dataset as those with only one tournament to their name from March can be compared to those who have multiple tournaments from other months not including March. \n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-1_52fdc14bda769b98868daec5a68fd8a5'}\n\n:::\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-2_dedf5c61c71abc3a3e99130d5f1d973f'}\n\n:::\n\n# Statistical Background \nIf you're not interested in the general theory of sampling variability feel free to skip this section. \n\nWhen sampling from a distribution we can generally expect that larger samples are going to include more extreme values from the tails which will greatly influence values such as maximums or minimums. In our discussion of chess our focus is on detecting if the difference between the greatest ELO values is influenced by this sampling size behavior. Because visually we can see that there is a long thin right tail after 2500 ELO.\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-3_fb1711d9e11540b5b47ea268b1d46b3b'}\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n## Heavy tails\nIn order to demonstrate on a toy example we can sample from a heavy-tailed distribution and see how our maximums and minimums change as the sample size changes. Visually we can see how the coverage of the x-axis increases with the increase in sample size in the plots below. \n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-4_09a13284f8c4ea6aa5b1b8bd0c22dc9f'}\n\n:::\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-5_8838bc552509752fedf1cada7589a283'}\n\n```{.r .cell-code}\n# Sample sizes to generate\nsample_sizes <- c(100, 1000, 10000)\n\n# Initialize list to store extremes for later comparison\nextremes <- list()\n\n# Generate samples and prepare for plotting\ndata <- data.frame()\nfor (size in sample_sizes) {\n  sample <- rcauchy(size)\n  \n  # Calculate and store extremes\n  min_val <- min(sample)\n  max_val <- max(sample)\n  extremes[[length(extremes) + 1]] <- c(min_val, max_val)\n  \n  # Prepare data for plotting\n  temp_data <- data.frame(Value = sample, Size = factor(size))\n  data <- rbind(data, temp_data)\n}\n\n# Filter the data to remove extreme values for better visualization\ndata <- subset(data, Value > -25 & Value < 25)\n\n# Plot using ggplot2\nggplot(data, aes(x=Value, fill=Size)) +\n  geom_histogram(bins=50, position=\"identity\", alpha=0.6) +\n  scale_fill_discrete(name=\"Sample Size\") +\n  labs(title=\"Comparison of Cauchy Samples\", x=\"Value\", y=\"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nAnd we find stark differences between the maximums and minimums in our samples.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-6_10afb748666887fc248fe9c0897ee64b'}\n\n```{.r .cell-code}\n# Print extremes\nfor (i in 1:length(sample_sizes)) {\n  size <- sample_sizes[i]\n  min_val <- extremes[[i]][1]\n  max_val <- extremes[[i]][2]\n  cat(sprintf(\"Sample size %d: Min %.2f, Max %.2f\\n\", size, min_val, max_val))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSample size 100: Min -27.65, Max 14.31\nSample size 1000: Min -138.42, Max 155.19\nSample size 10000: Min -1618.11, Max 3905.19\n```\n:::\n:::\n\n## Normal distribution\nEven for distributions that are not heavy-tailed such as the normal distribution with a mean of 0 and standard deviation of 1 we can see that the maximum and minimum values are increasing in absolute value for increasing sample sizes such that the minimum and the maximum get further from the mean. \n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-7_58707fc7f35ddfed600d6137fe422a8d'}\n\n```{.r .cell-code}\nextremes <- list()\ndata <- data.frame()\n\nfor (size in sample_sizes) {\n  sample <- rnorm(size)\n  \n  # Calculate and store extremes\n  min_val <- min(sample)\n  max_val <- max(sample)\n  mean_val <- mean(sample)\n  extremes[[length(extremes) + 1]] <- c(min_val, max_val)\n  \n  # Prepare data for plotting\n  temp_data <- data.frame(Value = sample, Size = factor(size), Mean = mean_val)\n  data <- rbind(data, temp_data)\n}\n\n# Filter the data to remove extreme values for better visualization\ndata <- subset(data, Value > -25 & Value < 25)\n\n# Plot using ggplot2\nggplot(data, aes(x=Value, fill=Size)) +\n  geom_histogram(bins=50, position=\"identity\", alpha=0.6) +\n  scale_fill_discrete(name=\"Sample Size\") +\n  labs(title=\"Comparison of Cauchy Samples\", x=\"Value\", y=\"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\nIt doesn't mean the samples are going to have their maximums or minimums deterministically increase with the increase of the sample size, but the probability that we sample a greater maximum or lower minimum increases as the sample size increases.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-8_20019db1b2dfe0d46cf6b51b7297c066'}\n\n```{.r .cell-code}\n# Print extremes\nfor (i in 1:length(sample_sizes)) {\n  size <- sample_sizes[i]\n  min_val <- extremes[[i]][1]\n  max_val <- extremes[[i]][2]\n  cat(sprintf(\"Sample size %d: Min %.2f, Max %.2f\\n\", size, min_val, max_val))}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSample size 100: Min -2.35, Max 2.75\nSample size 1000: Min -3.29, Max 3.72\nSample size 10000: Min -3.85, Max 3.85\n```\n:::\n:::\n\n\n\nWith all of this background in mind we can proceed to our analysis of the realworld data. \n\n# Analysis\nI begin by loading in the data, removing players who do not have a standard rating and ensuring that we do not include Juniors (<18 years old players) in our ratings as their ratings fluctuate more than those of older players. \n\nI begin by splitting our data by gender and looking at the basic stats. I find that the top 20 chess players in the world are *all* men for this data. Additionally we can see that the number of males in the sample is an order of magnitude larger than that of females while the difference in the top ELO is ~190 points.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-9_f9da03142eec18a82a9aa2689a7c93cf'}\n\n:::\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-10_af7f3c18a82c15525bbaea7a9a22bcd7'}\n\n```{.r .cell-code}\nbasic_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        Category  Value\n1   Male Max ELO   2863\n2 Female Max ELO   2675\n3     Count Male 238720\n4   Count Female  19806\n```\n:::\n:::\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-11_ee281b0035c5a172d7301fd1ba3cd1e5'}\n\n:::\n\nWe can see the names of the top 20 players in our data, and further the gender split which it turns out is entirely male.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-12_a8badda4bb482165d278d46d99ef5037'}\n\n```{.r .cell-code}\nrating_ordered <- rating[order(rating$average_rating_standard, decreasing = TRUE),]\nI_top <- head(rating_ordered, 20)\ntable(I_top$gender)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n M \n20 \n```\n:::\n\n```{.r .cell-code}\ntable(I_top$name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Anand, Viswanathan           Aronian, Levon      Artemiev, Vladislav \n                       1                        1                        1 \n         Carlsen, Magnus         Caruana, Fabiano              Ding, Liren \n                       1                        1                        1 \nDominguez Perez, Leinier              Giri, Anish      Grischuk, Alexander \n                       1                        1                        1 \n        Karjakin, Sergey          Kasparov, Garry        Kramnik, Vladimir \n                       1                        1                        1 \n  Mamedyarov, Shakhriyar         Nakamura, Hikaru      Nepomniachtchi, Ian \n                       1                        1                        1 \n       Radjabov, Teimour         Rapport, Richard               So, Wesley \n                       1                        1                        1 \n Vachier-Lagrave, Maxime               Yu, Yangyi \n                       1                        1 \n```\n:::\n:::\n\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-13_f2e0879a7c66264cb0de6bfba33a22f2'}\n\n:::\n\nHere we take some of the basic statistics of the male and female ratings and we can see that there is a ~100 point difference between the two groups' mean ELO.\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-14_b9728092a7274e6995f5106ac02344e5'}\n\n```{.r .cell-code}\nmu_std_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Category Value\n1                 mean Male  1769\n2               mean Female  1679\n3   standard deviation Male   311\n4 standard deviation Female   316\n```\n:::\n:::\n\n\nUsing the same method as Wei Ji, we do a permutation of the ratings without respect to gender. So what that means is we take the number of women and men in the sample, and draw samples with those same sizes from the pooled data. This means that we will get samples with the size of the same smaller size that women represent in our real data but including males. This will allow us to see how much of the variation between men and women is simply due to the fact that the sample of women who do chess is much smaller than that of men.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-15_845c4ab3fcfcf0a9dd250bad2169de95'}\n\n```{.r .cell-code}\nlibrary(parallel)\n\n# Assuming ndraws, n_large, rating$average_rating_standard are defined\nndraws <- 10000 # example value\nn_large <- n_M\nn_small <- n_F\n\n\n# Detect the number of available cores\nno_cores <- detectCores() - 1  \n\n# Define a function to perform what was originally in the loop\nperform_draw <- function(i) {\n  rating_perm <- sample(rating$average_rating_standard)\n  draw_large <- rating_perm[1:n_large]\n  draw_small <- rating_perm[(n_large + 1):length(rating_perm)]\n  \n  c(max_large = max(draw_large), max_small = max(draw_small))\n}\n\n# Use mclapply to run iterations in parallel\nresults <- mclapply(1:ndraws, perform_draw, mc.cores = no_cores)\n\n# Extract max_large and max_small from results\nmax_large <- sapply(results, `[[`, \"max_large\")\nmax_small <- sapply(results, `[[`, \"max_small\")\n```\n:::\n\nUsing the simulated samples above we can get an average difference between groups with these differing sizes as well as the standard deviation of this difference.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-16_d1ebc0783f4ec3c7ff2427a448d3d569'}\n\n```{.r .cell-code}\ndelta <- max_large - max_small\ndelta_mean <- mean(delta)\ndelta_std <- sd(delta)\n```\n:::\n\nHere is a graph where we can see that there are many fewer women than men who play chess, but their coverage of the ELO ratings is still similar.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-17_29a40c2bcb87e99ba7215067a8990d6e'}\n\n```{.r .cell-code}\nplot(rating_centers, h_M, type = 'o', xlab = 'Rating (binned)', ylab = 'Number of players',\n     xlim = c(1000, 2800), ylim = range(c(h_M, h_F)), main = 'Rating distributions of all players by gender 2019', col = 'blue')\npoints(rating_centers, h_F, type = 'o', col = 'red')\nlegend(\"topright\", legend=c(\"Male\", \"Female\"), col=c(\"blue\", \"red\"), pch=1)\n```\n\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\nHere we adjust the rating distributions by number of participants for both men and women in order to see if the shape and location of the distributions are significantly different. We can see the slight leftward shift in the female ratings distribution consistent with the ~90 rating point difference found earlier.\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-18_098a5874808402b3e841e6f66368c8c9'}\n\n```{.r .cell-code}\nplot(rating_centers, hn_M, type = 'o', xlab = 'Rating (binned)', ylab = 'Number of players',\n     xlim = c(1000, 2800), ylim = range(c(hn_M, hn_F)), main = 'Normalized rating distributions of all players by gender 2019', col = 'blue')\npoints(rating_centers, hn_F, type = 'o', col = 'red')\nlegend(\"topright\", legend=c(\"Male\", \"Female\"), col=c(\"blue\", \"red\"), pch=1)\n```\n\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\nHere we plot the distribution of differences found from the resampling process that we performed previously. The mean value is ~87 points difference between the simulated groups. \n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-19_e068825b146310af07122c163d76d5bf'}\n\n```{.r .cell-code}\nhist(delta, breaks = seq(-100, 500, by = 50), main = 'Difference between best M and best F',\n     xlab = 'Difference', ylab = 'Frequency/1000')\n```\n\n::: {.cell-output-display}\n![](chess_fide_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-20_9af583c6a835caaa74b5b7237ade2ec1'}\n\n```{.r .cell-code}\n# trying to see how much delta accounts for..\nrating_M_ordered <- rating_M[order(rating_M$average_rating_standard, decreasing = TRUE),]\nI_top_M <- head(rating_M_ordered, 20)\n\nrating_F_ordered <- rating_F[order(rating_F$average_rating_standard, decreasing = TRUE),]\nI_top_F <- head(rating_F_ordered, 20)\n\nmean(I_top_M$average_rating_standard) - mean(I_top_F$average_rating_standard)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 231.0042\n```\n:::\n:::\nWe use a two-tailed t-test in order to see if there is a significant difference between the average of the delta between the simulated maximum male sized group ELO and the simulated maximum female sized group ELO and the real difference between the maximum Male ELO and the maximum Female ELO. We use a two-tailed t-test because we wish to detect a difference between the simulated and real deltas in either direction. \n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-21_ba02b0fbbd2522629f793afa8043cf1f'}\n\n```{.r .cell-code}\nz <- ((max_M - max_F) - delta_mean) / delta_std\n# Calculate two-tailed p-value\np_value <- 2 * (1 - pnorm(abs(z)))\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04241901\n```\n:::\n:::\n\nWe find at a significance of 0.01 that there is no difference between the simulated and the real difference in the top ELOs of men and women. From this we can see that a primary explanation of the male-female performance gap is simply a pipeline issue. The underlying distribution of male and female performance is the same, the difference comes only from the fact that the number of males competing in chess dwarfs that of females. Additionally I perform a power analysis to see that the result is well powered and we should have detected a difference outside of sampling variability were there one.\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-22_531e194ad8b3b7cd4146186b395834a9'}\n\n```{.r .cell-code}\neffect_size <- 0.1\nalpha <- 0.01\npower <- 0.95\nsample_size <- NULL  # If you want to calculate sample size, set this to NULL\n\n# Perform power analysis\nresult <- pwr.t.test(d = effect_size, sig.level = alpha, power = power,\n                     n = sample_size, alternative = \"two.sided\")\n\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 3564.492\n              d = 0.1\n      sig.level = 0.01\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\nConsidering our sample size (males and females together) is ~258000 individual observations and the sample of our simulated deltas is 10000, our analysis satisfies a fairly strict power threshold and would detect a very small effect (Cohen's d of 0.1) at an alpha of 0.01, detecting a true effect with 95% probability. Thus we can be fairly certain in our results.\n\n\n\n## Additional notes on sampling variability\n\nWe can get a good baseline estimate for how often it is that a small sample has a larger maximum than a larger sample from the same distribution from the normal distribution. Here we can see that less than ten percent of the time we should expect the smaller sample to have a larger maximum even from the *same distribution!* The gendered differences in results we can observe in the chess world are probably coming from the fact that there are so many fewer women participating.\n\n::: {.cell hash='chess_fide_cache/html/unnamed-chunk-23_ea36e86e6d2538b59850ebb10c72836d'}\n\n```{.r .cell-code}\n# Sample sizes to compare (scaled down)\nsample_size_small <- 2000\nsample_size_large <- 24000\n\n# Initialize counter for tracking when the smaller sample has a larger maximum\ncounter <- 0\n\n# Number of iterations\niterations <- 10000\n\n# Loop for performing the comparison across iterations\nfor (i in 1:iterations) {\n  # Generate samples for each size\n  sample_small <- rnorm(sample_size_small)\n  sample_large <- rnorm(sample_size_large)\n  \n  # Compare max values and update counter if smaller sample has a larger max\n  if (max(sample_small) > max(sample_large)) {\n    counter <- counter + 1\n  }\n}\n\n# Calculate the percentage\npercentage <- counter / iterations * 100\n\n# Print the result\ncat(\"Percentage of times the smaller sample (2000) has a larger maximum than the larger sample (24000):\", percentage, \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPercentage of times the smaller sample (2000) has a larger maximum than the larger sample (24000): 7.86 %\n```\n:::\n:::\n\n<!-- \nLimitation: we can only detect effects when the shifts are large. So sensitivity for detecting differences in sample maxes is low! For the following we take a toy model to represent our chess data, we generate two samples from distributions where the smaller is shifted anywhere from 2 standard deviations to the left and not at all. Then we combine those two distributions in the same way as before and see how the maxes of representative draws from the combined distribution differ. Then we conduct a two-tailed t-test in order to determine if there is a significant difference between the maxes of our two samples given the permuted dataset for each level of mean shift. \n\nOverall (and as expected) small shifts mean difficulty detecting a difference in the two distributions. Our real world female data has a mean difference of 0.29 sd compared to the male data which means our ability to detect differences in the maximums is quite low.\n\n#| code-fold: true\n\nlibrary(parallel)\n\n# Parameters for the normal distributions\nmean_large <- 0\nsd_large <- 1\n\n# Number of iterations and sample sizes\nsample_size_small <- 2000\nsample_size_large <- 24000\niterations <- 10000\n\n# Vector of mean shifts to test\nmean_shifts <- seq(-2, 0, by=0.1)\n\n# Create a cluster of worker processes\ncl <- makeCluster(detectCores() - 1)  # Use one less than the total number of cores\n\n# Export necessary variables and functions to the cluster\nclusterExport(cl, c(\"mean_large\", \"sd_large\", \"sample_size_small\", \"sample_size_large\", \"iterations\", \"rnorm\", \"sample\"))\n\n# Define a function to perform permutation tests for a given mean shift\nperform_test <- function(mean_shift) {\n  mean_small <- mean_large - mean_shift * sd_large\n  sample_small <- rnorm(sample_size_small, mean_small, sd_large)\n  sample_large <- rnorm(sample_size_large, mean_large, sd_large)\n  mixed_sample <- c(sample_small, sample_large)\n  delta_sim_shift <- numeric(iterations)\n  for (i in 1:iterations) {\n\n    \n    mixed_sample_perm <- sample(mixed_sample)\n    draw_large <- mixed_sample_perm[1:sample_size_large]\n    draw_small <- mixed_sample_perm[(sample_size_large + 1):length(mixed_sample_perm)]\n    \n    delta_sim_shift[i] <- max(draw_large) - max(draw_small)\n  }\n  \n  max_diff_shift <- max(sample_large) - max(sample_small)\n  delta_mean_shift <- mean(delta_sim_shift)\n  delta_std_shift <- sd(delta_sim_shift)\n  \n  z <- (max_diff_shift - delta_mean_shift) / delta_std_shift\n  p_value <- 2 * (1 - pnorm(abs(z)))\n  \n  return(p_value)\n  # return(max_diff_shift)\n\n}\n\n# Parallelize the loop over mean shifts\np_values <- parLapply(cl, mean_shifts, perform_test)\n\n# Stop the cluster\nstopCluster(cl)\n\n# Optionally, identify which shifts lead to rejecting the null hypothesis at a given significance level\nsignificance_level <- 0.05\nrejected_shifts <- mean_shifts[unlist(p_values) < significance_level]\nprint(rejected_shifts)\n\n\nbaru_penahan <- data.frame(Mean_Shift = mean_shifts, P_Value = unlist(p_values))\nbaru_penahan\n```\n\n\n<!-- #TODO: use resampling from our dist and subtract -x SD from some random draw from it, readd then sample again to see if difference can be detected.. -->\n<!-- \n#| code-fold: true\nlibrary(parallel)\n\n\n# Create a cluster of worker processes\ncl <- makeCluster(detectCores() - 1)  # Use one less than the total number of cores\n\nndraws <- 10000 # example value\nn_large <- n_M\nn_small <- n_F\n\n# Calculate the standard deviation of the smaller distribution or the overall dataset\nsd_small <- sd(rating_F$average_rating_standard)\n\n# Define desired effect sizes (Cohen's D values)\ncohen_ds <- seq(-2, 0, by=0.1)  # Example range, adjust as needed\n\n# Convert Cohen's D values to mean shifts\nmean_shifts <- cohen_ds * sd_small\n\n\nmax_diff_no_shift <- max(rating$average_rating_standard[1:n_large]) - max(rating$average_rating_standard[(n_large + 1):length(rating$average_rating_standard)])\n\n\n\n# Export necessary variables to the cluster\nclusterExport(cl, c(\"rating\", \"n_large\", \"n_small\", \"mean_shifts\", \"sd_small\", \"ndraws\", \"max_diff_no_shift\"))\n\n\nperform_shift_test <- function(mean_shift) {\n  # Initialize a numeric vector to store the results of each iteration\n  results_shift <- numeric(ndraws)\n  \n  for (i in 1:ndraws) {\n    rating_perm <- sample(rating$average_rating_standard)\n    draw_large <- rating_perm[1:n_large]\n    # Apply mean shift to small distribution\n    draw_small_shifted <- rating_perm[(n_large + 1):length(rating_perm)] + mean_shift\n    \n    max_diff_shift <- max(draw_large) - max(draw_small_shifted)\n    \n    # Store the result of this iteration\n    results_shift[i] <- max_diff_shift\n  }\n  \n  # Statistical analysis to determine significance of shift effect\n  delta_mean_shift <- mean(results_shift)\n  delta_std_shift <- sd(results_shift)\n  # Assuming max_diff_no_shift for no shift scenario is pre-calculated or defined\n  z <- (max_diff_no_shift - delta_mean_shift) / delta_std_shift\n  p_value <- 2 * (1 - pnorm(abs(z)))\n  \n  return(p_value)\n}\n\n\n# Parallelize the loop over mean shifts\np_values <- parLapply(cl, mean_shifts, perform_shift_test)\n\n\n\n# Stop the cluster\nstopCluster(cl)\n\n# Optionally, identify which shifts lead to rejecting the null hypothesis at a given significance level\nsignificance_level <- 0.01\nrejected_shifts <- mean_shifts[unlist(p_values) < significance_level]\nprint(rejected_shifts)\n\n\nbaru_penahan <- data.frame(Mean_Shift = mean_shifts, P_Value = unlist(p_values))\nbaru_penahan\n``` -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}